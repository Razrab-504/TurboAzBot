import asyncio
import random
import logging
from bs4 import BeautifulSoup
import ssl
import certifi
import requests
from requests.auth import HTTPBasicAuth
from urllib.parse import quote

from src.db.session import Local_Session

from src.db.crud.advertisement_crud import get_ad_by_id, create_ad
from src.db.crud.sent_ad_crud import is_ad_sent_to_user, create_sent_ad
from src.db.crud.user_crud import update_user
from src.db.models import User
from sqlalchemy import select
from sqlalchemy.orm import joinedload
from aiogram import Bot
import datetime
import os

async def parse_page(url: str, max_retries: int = 3) -> list:
    api_key = os.getenv("SCRAPING_API_KEY")
    if not api_key:
        logging.error("SCRAPING_API_KEY not set")
        return []

    for attempt in range(max_retries):
        try:
            scraping_url = f"https://api.scrapingapi.com/scrape?api_key={api_key}&url={quote(url)}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: –ü–∞—Ä—Å–∏–Ω–≥ URL –¥–ª–∏–Ω–æ–π {len(url)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            response = requests.get(
                scraping_url,
                headers=headers,
                timeout=90,
                verify=False
            )

            logging.info(f"–°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")

            if response.status_code == 400:
                error_text = response.text[:300]
                logging.error(f"–û—à–∏–±–∫–∞ 400 - –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
                logging.error(f"URL: {url}")
                logging.error(f"–û—Ç–≤–µ—Ç API: {error_text}")
                return []

            if response.status_code == 403:
                logging.error("–û—à–∏–±–∫–∞ 403 - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á –∏–ª–∏ –±–∞–ª–∞–Ω—Å")
                return []

            if response.status_code == 429:
                logging.error("–û—à–∏–±–∫–∞ 429 - –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤")
                if attempt < max_retries - 1:
                    await asyncio.sleep(random.uniform(30, 60))
                    continue
                return []

            if response.status_code != 200:
                error_text = response.text[:300]
                logging.error(f"–û—à–∏–±–∫–∞ {response.status_code}: {error_text}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(random.uniform(5, 10))
                    continue
                return []

            html = response.text

            if len(html) < 500:
                logging.warning(f"–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: {len(html)} –±–∞–π—Ç")
                if attempt < max_retries - 1:
                    await asyncio.sleep(random.uniform(5, 10))
                    continue
                return []

            soup = BeautifulSoup(html, 'lxml')
            ads = []
            cards = soup.find_all('div', class_='products-i')
            
            logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π")

            for card in cards:
                try:
                    link_tag = card.find('a', class_='products-i__link')
                    if not link_tag or 'href' not in link_tag.attrs:
                        continue

                    ad_url = 'https://turbo.az' + link_tag['href']
                    ad_id = ad_url.split('/')[-1].split('?')[0]

                    title_tag = card.find('div', class_='products-i__name')
                    title = title_tag.text.strip() if title_tag else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'

                    price_tag = card.find('div', class_='product-price')
                    price = price_tag.text.strip() if price_tag else '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'

                    img_tag = card.find('img', class_='products-i__photo')
                    img_url = ''
                    if img_tag:
                        img_url = img_tag.get('data-src') or img_tag.get('src', '')

                    datetime_tag = card.find('div', class_='products-i__datetime')
                    datetime_str = datetime_tag.text.strip() if datetime_tag else ''

                    ads.append({
                        'id': ad_id,
                        'title': title,
                        'price': price,
                        'url': ad_url,
                        'img': img_url,
                        'city': datetime_str.split(',')[0] if ',' in datetime_str else '',
                        'published_at': datetime_str.split(',')[1].strip() if ',' in datetime_str else datetime_str
                    })
                except Exception as e:
                    logging.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                    continue

            logging.info(f"–£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ {len(ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
            return ads
            
        except requests.exceptions.Timeout:
            logging.error(f"Timeout –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")
            if attempt < max_retries - 1:
                await asyncio.sleep(random.uniform(10, 15))
                continue
            return []
            
        except Exception as e:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                await asyncio.sleep(random.uniform(5, 10))
                continue
            return []
    
    return []

async def notify_admins(bot: Bot, message: str):
    async with Local_Session() as session:
        result = await session.execute(select(User).where(User.role == "admin"))
        admins = result.scalars().all()
        for admin in admins:
            try:
                await bot.send_message(admin.id, f"‚ö†Ô∏è {message}")
            except Exception as e:
                logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É {admin.id}: {e}")

async def check_expired_subscriptions():
    async with Local_Session() as session:
        now = datetime.datetime.utcnow()
        result = await session.execute(
            select(User)
            .where(User.subscription == True)
            .where(User.expiry_date.isnot(None))
            .where(User.expiry_date < now)
        )
        expired_users = result.scalars().all()
        for user in expired_users:
            await update_user(session, user.id, subscription=False)
            logging.info(f"–ü–æ–¥–ø–∏—Å–∫–∞ –∏—Å—Ç–µ–∫–ª–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.id}")

async def parse_user_filters(bot: Bot):
    logging.info("–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤")
    await check_expired_subscriptions()

    async with Local_Session() as session:
        result = await session.execute(
            select(User)
            .options(joinedload(User.filters))
            .where(User.subscription == True)
        )
        users = result.scalars().unique().all()
        logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –ø–æ–¥–ø–∏—Å–∫–æ–π")

        url_to_users = {}
        for user in users:
            for filter_ in user.filters:
                if filter_.query_url not in url_to_users:
                    url_to_users[filter_.query_url] = []
                url_to_users[filter_.query_url].append((user.id, filter_))

        logging.info(f"–ü–∞—Ä—Å–∏–Ω–≥ {len(url_to_users)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö URL")

        for url, user_filters in url_to_users.items():
            try:
                ads = await parse_page(url)
                logging.info(f"–î–ª—è URL –Ω–∞–π–¥–µ–Ω–æ {len(ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
                
                if len(ads) == 0:
                    logging.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –¥–ª—è URL: {url}")
                    
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
                await notify_admins(bot, f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)[:100]}")
                continue

            for user_id, filter_ in user_filters:
                parts = filter_.label.split()
                make = parts[0].lower() if len(parts) > 0 else ''
                model = " ".join(parts[1:-1]).lower() if len(parts) > 2 else (parts[1].lower() if len(parts) > 1 else '')

                filtered_ads = []
                for ad in ads:
                    title_lower = ad['title'].lower()
                    if make and make not in title_lower:
                        continue
                    if model and model not in title_lower:
                        continue
                    filtered_ads.append(ad)

                logging.info(f"–î–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} —Ñ–∏–ª—å—Ç—Ä '{filter_.label}' –ø—Ä–æ—à–µ–ª {len(filtered_ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")

                for ad in filtered_ads:
                    existing = await get_ad_by_id(session, ad['id'])
                    if not existing:
                        await create_ad(session, ad)

                    sent = await is_ad_sent_to_user(session, user_id, ad['id'])
                    if not sent:
                        city = ad.get('city', '')
                        pub = ad.get('published_at', '')
                        location = f"üìç {city}" if city else ""
                        time_info = f"‚è∞ {pub}" if pub else ""
                        caption = f"<b>{ad['title']}</b>\n\nüí∞ {ad['price']}\n{location}\n{time_info}\nüîó {ad['url']}"
                        try:
                            if ad.get('img'):
                                await bot.send_photo(
                                    chat_id=user_id,
                                    photo=ad['img'],
                                    caption=caption,
                                    parse_mode='HTML'
                                )
                            else:
                                await bot.send_message(
                                    chat_id=user_id,
                                    text=caption,
                                    parse_mode='HTML'
                                )
                            logging.info(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ {ad['id']} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}")
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {e}")
                            try:
                                await bot.send_message(
                                    chat_id=user_id,
                                    text=caption,
                                    parse_mode='HTML'
                                )
                            except Exception as e2:
                                logging.error(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {e2}")
                        
                        await create_sent_ad(session, user_id, ad['id'])

            delay = random.uniform(10, 20)
            await asyncio.sleep(delay)

async def start_parsing_loop(bot: Bot):
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    while True:
        try:
            await parse_user_filters(bot)
        except Exception as e:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            await notify_admins(bot, f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)[:100]}")
        
        delay = random.uniform(120, 180)  # 2-3 –º–∏–Ω—É—Ç—ã –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏
        logging.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {delay:.0f} —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞")
        await asyncio.sleep(delay)